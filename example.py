import openai
import streamlit as st
import toml
from streamlit_chat import message

# Set page title and header
st.set_page_config(page_title="WDC", page_icon=":globe_with_meridians:")

st.markdown("<h1 style='text-align: center;'>World Disaster Center üåê</h1>", unsafe_allow_html=True)

# Load API key from environment variable
openai.api_key = st.secrets["API_KEY"]


# Initialize session state
if 'generated' not in st.session_state:
    st.session_state['generated'] = []
if 'past' not in st.session_state:
    st.session_state['past'] = []
if 'messages' not in st.session_state:
    st.session_state['messages'] = [{"role": "system", "content": "You are a helpful assistant for disaster and natural catastrophe information."}]
if 'model_name' not in st.session_state:
    st.session_state['model_name'] = []
if 'cost' not in st.session_state:
    st.session_state['cost'] = []
if 'total_tokens' not in st.session_state:
    st.session_state['total_tokens'] = []
if 'total_cost' not in st.session_state:
    st.session_state['total_cost'] = 0.0

# Sidebar for model selection, cost display, and conversation clearing
st.sidebar.title("World Disaster Center")
#model_name = st.sidebar.radio("Choose a model:", ("GPT-3.5", "GPT-4"))
model_name = "GPT-3.5"
counter_placeholder = st.sidebar.empty()
# counter_placeholder.write(f"Total cost of this conversation: ${st.session_state['total_cost']:.5f}")
clear_button = st.sidebar.button("Clear Conversation", key="clear")

# Map model names to OpenAI model IDs
model = "gpt-3.5-turbo" #if model_name == "GPT-3.5" #else "gpt-4"

# Clear conversation
if clear_button:
    st.session_state['generated'] = []
    st.session_state['past'] = []
    st.session_state['messages'] = [{"role": "system", "content": "You are a helpful assistant for disaster and natural catastrophe information."}]
    st.session_state['model_name'] = []
    st.session_state['cost'] = []
    st.session_state['total_cost'] = 0.0
    st.session_state['total_tokens'] = []
    counter_placeholder.write(f"Total cost of this conversation: ${st.session_state['total_cost']:.5f}")

# Function to check if the question is disaster-related
def is_disaster_related(question):
    keywords = keywords = [
    "disaster", "catastrophe", "emergency", "evacuation", "rescue", "flood", "fire", "earthquake", "hurricane", "cyclone", "tsunami", "landslide", "volcano", "drought", "storm", "tornado", "hailstorm", "blizzard", "avalanche", "heatwave", "aftershock", "wildfire", "mudslide", "storm surge", "lightning", "sinkhole", "famine", "epidemic", "contamination", "radiation", "explosion", "meltdown", "pestilence", "plague", "collapse", "severe weather", "sandstorm", "tropical storm",
    "d√©sastre", "catastrophe", "urgence", "√©vacuation", "secours", "inondation", "incendie", "tremblement de terre", "ouragan", "cyclone", "tsunami", "glissement de terrain", "volcan", "s√©cheresse", "temp√™te", "tornade", "orage de gr√™le", "blizzard", "avalanche", "canicule", "r√©plique", "feu de for√™t", "coul√©e de boue", "onde de temp√™te", "foudre", "dolline", "famine", "√©pid√©mie", "contamination", "radiation", "explosion", "fusion", "peste", "effondrement", "intemp√©ries", "temp√™te de sable", "temp√™te tropicale",
    "desastre", "cat√°strofe", "emergencia", "evacuaci√≥n", "rescate", "inundaci√≥n", "incendio", "terremoto", "hurac√°n", "cicl√≥n", "tsunami", "deslizamiento", "volc√°n", "sequ√≠a", "tormenta", "tornado", "granizada", "ventisca", "avalancha", "ola de calor", "r√©plica", "incendio forestal", "deslizamiento de lodo", "marejada cicl√≥nica", "rel√°mpago", "sumidero", "hambruna", "epidemia", "contaminaci√≥n", "radiaci√≥n", "explosi√≥n", "fusi√≥n", "pestilencia", "plaga", "colapso", "clima severo", "tormenta de arena", "tormenta tropical",
    "desastre", "cat√°strofe", "emerg√™ncia", "evacua√ß√£o", "resgate", "inunda√ß√£o", "inc√™ndio", "terremoto", "furac√£o", "ciclone", "tsunami", "deslizamento de terra", "vulc√£o", "seca", "tempestade", "tornado", "tempestade de granizo", "nevasca", "avalanche", "onda de calor", "r√©plica", "inc√™ndio florestal", "deslizamento de lama", "ressaca", "raio", "dolina", "fome", "epidemia", "contamina√ß√£o", "radia√ß√£o", "explos√£o", "colapso", "praga", "peste", "colapso", "tempo severo", "tempestade de areia", "tempestade tropical",
    "–±–µ–¥—Å—Ç–≤–∏–µ", "–∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∞", "—á—Ä–µ–∑–≤—ã—á–∞–π–Ω–∞—è —Å–∏—Ç—É–∞—Ü–∏—è", "—ç–≤–∞–∫—É–∞—Ü–∏—è", "—Å–ø–∞—Å–µ–Ω–∏–µ", "–Ω–∞–≤–æ–¥–Ω–µ–Ω–∏–µ", "–ø–æ–∂–∞—Ä", "–∑–µ–º–ª–µ—Ç—Ä—è—Å–µ–Ω–∏–µ", "—É—Ä–∞–≥–∞–Ω", "—Ü–∏–∫–ª–æ–Ω", "—Ü—É–Ω–∞–º–∏", "–æ–ø–æ–ª–∑–µ–Ω—å", "–≤—É–ª–∫–∞–Ω", "–∑–∞—Å—É—Ö–∞", "—à—Ç–æ—Ä–º", "—Ç–æ—Ä–Ω–∞–¥–æ", "–≥—Ä–∞–¥", "–º–µ—Ç–µ–ª—å", "–ª–∞–≤–∏–Ω–∞", "–∂–∞—Ä–∞", "–∞—Ñ—Ç–µ—Ä—à–æ–∫", "–ª–µ—Å–Ω–æ–π –ø–æ–∂–∞—Ä", "–æ–ø–æ–ª–∑–µ–Ω—å –∏–∑ –≥—Ä—è–∑–∏", "—à—Ç–æ—Ä–º–æ–≤–æ–π –Ω–∞–≥–æ–Ω", "–º–æ–ª–Ω–∏—è", "–∫–∞—Ä—Å—Ç–æ–≤–∞—è –≤–æ—Ä–æ–Ω–∫–∞", "–≥–æ–ª–æ–¥", "—ç–ø–∏–¥–µ–º–∏—è", "–∑–∞—Ä–∞–∂–µ–Ω–∏–µ", "—Ä–∞–¥–∏–∞—Ü–∏—è", "–≤–∑—Ä—ã–≤", "—Ä–∞—Å–ø–ª–∞–≤–ª–µ–Ω–∏–µ", "–º–æ—Ä", "—á—É–º–∞", "–∫–æ–ª–ª–∞–ø—Å", "—Å–∏–ª—å–Ω–∞—è –ø–æ–≥–æ–¥–∞", "–ø–µ—Å—á–∞–Ω–∞—è –±—É—Ä—è", "—Ç—Ä–æ–ø–∏—á–µ—Å–∫–∏–π —à—Ç–æ—Ä–º"
]
    return any(keyword in question.lower() for keyword in keywords)

# Generate response
def generate_response(prompt):
    if not is_disaster_related(prompt):
        response = "I can only answer questions related to disasters and catastrophes. Please rephrase your question."
        return response, 0, 0, 0

    st.session_state['messages'].append({"role": "user", "content": prompt})

    try:
        completion = openai.ChatCompletion.create(
            model=model,
            messages=st.session_state['messages']
        )
        response = completion.choices[0].message.content
        st.session_state['messages'].append({"role": "assistant", "content": response})

        total_tokens = completion.usage.total_tokens
        prompt_tokens = completion.usage.prompt_tokens
        completion_tokens = completion.usage.completion_tokens

        return response, total_tokens, prompt_tokens, completion_tokens

    except Exception as e:
        st.error(f"An error occurred: {e}")
        return "", 0, 0, 0

# Chat containers
response_container = st.container()
container = st.container()

with container:
    with st.form(key='my_form', clear_on_submit=True):
        user_input = st.text_area("You:", key='input', height=100)
        submit_button = st.form_submit_button(label='Send')

    if submit_button and user_input:
        output, total_tokens, prompt_tokens, completion_tokens = generate_response(user_input)
        st.session_state['past'].append(user_input)
        st.session_state['generated'].append(output)
        st.session_state['model_name'].append(model_name)
        st.session_state['total_tokens'].append(total_tokens)


if st.session_state['generated']:
    with response_container:
        for i in range(len(st.session_state['generated'])):
            message(st.session_state["past"][i], is_user=True, key=str(i) + '_user')
            message(f"üåê {st.session_state['generated'][i]}", key=str(i))




